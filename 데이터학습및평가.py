# -*- coding: utf-8 -*-
# === 5. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (Phase 5) ===
# ì„¤ëª…: ìµœì¢… ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸(Random Forest)ì„ í•™ìŠµì‹œí‚¤ê³ ,
#       ì‹¤ì œ ì•„íŒŒíŠ¸ ë§¤ë§¤ê°€ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import platform
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor

# ----------------------------------------------------------
# 1. í•œê¸€ í°íŠ¸ ì„¤ì • (Mac/Windows í˜¸í™˜)
# ----------------------------------------------------------
system_name = platform.system()
if system_name == 'Darwin': # Mac
    plt.rcParams['font.family'] = 'AppleGothic'
elif system_name == 'Windows': # Windows
    plt.rcParams['font.family'] = 'Malgun Gothic'
else: # Linux (Colab ë“±)
    plt.rcParams['font.family'] = 'NanumGothic'

plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€

# ----------------------------------------------------------
# 2. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ----------------------------------------------------------
INPUT_FILE = 'apartment_sales_final_features.csv'

def train_and_evaluate():
    print("--- ë§¤ë§¤ê°€ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(INPUT_FILE):
        print(f"[ì˜¤ë¥˜] '{INPUT_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(">>> 'ë°ì´í„°ë¶„ì„.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì„œ í•™ìŠµìš© ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”!")
        return

    # ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ì²˜ë¦¬)
    try:
        df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig')
    except UnicodeDecodeError:
        df = pd.read_csv(INPUT_FILE, encoding='cp949')

    print(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(df)}ê±´")

    # ----------------------------------------------------------
    # 3. ë°ì´í„° ë¶„í•  (í•™ìŠµìš© vs í…ŒìŠ¤íŠ¸ìš©)
    # ----------------------------------------------------------
    target_col = 'log_ê±°ë˜ê¸ˆì•¡' # íƒ€ê²Ÿ ë³€ìˆ˜ (ë¡œê·¸ ë³€í™˜ëœ ê°€ê²©)

    # X: íƒ€ê²Ÿì„ ì œì™¸í•œ ëª¨ë“  íŠ¹ì„±, y: íƒ€ê²Ÿ
    X = df.drop(columns=[target_col])
    y = df[target_col]

    # 80% í•™ìŠµ, 20% í…ŒìŠ¤íŠ¸
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"ë°ì´í„° ë¶„í•  ì™„ë£Œ: í•™ìŠµìš© {len(X_train)}ê±´, í…ŒìŠ¤íŠ¸ìš© {len(X_test)}ê±´")

    # ----------------------------------------------------------
    # 4. ëª¨ë¸ í•™ìŠµ (Random Forest)
    # ----------------------------------------------------------
    print("\n[AI ëª¨ë¸ í•™ìŠµ ì¤‘...] ìˆ²(Forest)ì„ í‚¤ìš°ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œ ëŒ€ê¸°)")
    
    # RandomForestRegressor: ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ê°•ë ¥í•œ ëª¨ë¸
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # ----------------------------------------------------------
    # 5. ì˜ˆì¸¡ ë° í‰ê°€
    # ----------------------------------------------------------
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (ê²°ê³¼ëŠ” ë¡œê·¸ ìŠ¤ì¼€ì¼)
    y_pred_log = model.predict(X_test)

    # ë¡œê·¸ ìŠ¤ì¼€ì¼ -> ì›ë˜ ê°€ê²©(ë§Œì›)ìœ¼ë¡œ ë³µì› (np.expm1)
    y_test_origin = np.expm1(y_test)
    y_pred_origin = np.expm1(y_pred_log)

    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    r2 = r2_score(y_test_origin, y_pred_origin)
    rmse = np.sqrt(mean_squared_error(y_test_origin, y_pred_origin))
    mae = mean_absolute_error(y_test_origin, y_pred_origin)

    print("\n" + "="*50)
    print(" ğŸ  ì•„íŒŒíŠ¸ ë§¤ë§¤ê°€ ì˜ˆì¸¡ AI ìµœì¢… ì„±ì í‘œ ğŸ ")
    print("="*50)
    print(f" 1. ì˜ˆì¸¡ ì •í™•ë„ (R2 Score) : {r2:.4f} (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì™„ë²½)")
    print(f" 2. í‰ê·  ì˜¤ì°¨ (RMSE)       : {rmse:,.0f} ë§Œì›")
    print(f" 3. í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)   : {mae:,.0f} ë§Œì›")
    print("-" * 50)
    print(f" í•´ì„: AIê°€ ì˜ˆì¸¡í•œ ê°€ê²©ì€ ì‹¤ì œ ê±°ë˜ê°€ê²©ê³¼ í‰ê· ì ìœ¼ë¡œ")
    print(f"       ì•½ {mae/10000:.2f}ì–µ ì› ({mae:,.0f}ë§Œì›) ì •ë„ ì°¨ì´ê°€ ë‚©ë‹ˆë‹¤.")
    print("="*50)

    # ----------------------------------------------------------
    # 6. ì‹œê°í™” (ê²°ê³¼ ë¶„ì„)
    # ----------------------------------------------------------
    
    # (1) ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=y_test_origin, y=y_pred_origin, alpha=0.6, color='#4c72b0')
    
    # ê¸°ì¤€ì„  (ì™„ë²½í•˜ê²Œ ë§ì¶˜ ê²½ìš°)
    min_val = min(y_test_origin.min(), y_pred_origin.min())
    max_val = max(y_test_origin.max(), y_pred_origin.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='ì™„ë²½í•œ ì˜ˆì¸¡ì„ ')
    
    plt.title(f'ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ ê²°ê³¼ (R2: {r2:.2f})', fontsize=14)
    plt.xlabel('ì‹¤ì œ ê±°ë˜ê°€ (ë§Œì›)', fontsize=12)
    plt.ylabel('AI ì˜ˆì¸¡ê°€ (ë§Œì›)', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    # (2) íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance)
    # ì–´ë–¤ ë³€ìˆ˜ê°€ ì§‘ê°’ ê²°ì •ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ í™•ì¸
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values(by='importance', ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=feature_importance, palette='viridis')
    plt.title('ì•„íŒŒíŠ¸ ì§‘ê°’ ê²°ì • ì¤‘ìš” ìš”ì¸ (Feature Importance)', fontsize=14)
    plt.xlabel('ì¤‘ìš”ë„', fontsize=12)
    plt.ylabel('ìš”ì¸(Feature)', fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    train_and_evaluate()